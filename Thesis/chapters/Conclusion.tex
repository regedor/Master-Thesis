\thispagestyle{empty}
\chapter{Conclusion}\label{chap:conclusion}


Nowadays, thousands of open-source software packages can be found and freely downloaded online.
github is a web-based hosting service for projects that use the Git revision control system.
It hosts more than 1 million open-source projects.

There is little work done concerning the measurement of coding standards by automatic analyzing source code.
We strongly believe that some research and development should be done in this direction.
Along the paper we gave arguments in order to make evident that it is worthwhile to detect on the source code
that the author follows the best practices recommended by the respective community.

In this particular context, Ruby Community, there is already some work done.
The  reports generated by the existent source code analyzers,
can spot the occurrences of bad smells but this is not enough.
There is the need to interpret those results to end up with a high level quality statement.
By comparing some projects, it was possible to start understanding how to interpret those values.
For instance, the \emph{size of the project} should be taken into consideration
(it is intuitive that a project with 10 lines of code and 10 errors is worse than a project with 1000 and 20 errors).
From the study we carried out and, described in the paper,
we also have learned that each best practice has a different importance level
--- 1 error that  affects security or performance is, for sure, worse than 10 errors related to indentation;
or 10 errors related to naming conventions are worse than the indentation mistakes).

We do believe that by analyzing a massive amount of open source projects,
it is possible to create a new set of metrics capable of quantify the standards followed by a given project,
judge the impact of the metrics evaluated
and consequently assess its level of maintainability.

The future work is to develop a system capable of automatically produce quality reports about a given OSSP
combining traditional SW metrics with best practices analysis.

This system will enable users to make better choices about what software to use and help developers to improve their software.







As future work, we are considering more correlations with other variables that are already available, but we haven't used yet. The most relevant ones: the number of commiters, starting date of the project, last commit data, and total number of commits. We believe that those variables can strongly be related with the forks, watchers and of course, in the end, the quality of the project.

